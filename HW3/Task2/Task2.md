# Task2 — Аппроксимация численности населения США

## Цель

* Используя многочлены степеней $N = 2, 3, 4, 5$ построить аппроксимацию по двум различным базисам.
* Использовать построенные приближения для предсказания численности населения США в 2010 году.

---

## Данные

| Год  | Население   |
| ---- | ----------- |
| 1910 | 92,228,496  |
| 1920 | 106,021,537 |
| 1930 | 123,202,624 |
| 1940 | 132,164,569 |
| 1950 | 151,325,798 |
| 1960 | 179,323,175 |
| 1970 | 203,211,926 |
| 1980 | 226,545,805 |
| 1990 | 248,709,873 |
| 2000 | 281,421,906 |

Точное значение для 2010 года — **308,745,538**.

---

## Реализация

### Базисы для аппроксимации
- $(x - 1910)^n$ для пункта (б).
```python
def basis_b(N):
    return [lambda x, n=n: (x - 1910)**n for n in range(N+1)]
```
- $(\frac{(x-1955)}{45})^n$ для пункта (г).
```python
def basis_d(N):
    return [lambda x, n=n: ((x - 1955)/45)**n for n in range(N+1)]
```

### Скалярное произведение и построение системы

```python
def dot_product(u, v):
    return np.dot(u, v)

def build_system(basis, y_values):
    n = len(basis)
    M = np.zeros((n, n))
    b = np.zeros(n)
    g = [b_func(years) for b_func in basis]

    for i in range(n):
        b[i] = dot_product(g[i], y_values)
        for j in range(n):
            M[i, j] = dot_product(g[i], g[j])
    return M, b
```

- `g[i]` — вектор значений i-го базиса в точках `years` (переходим от функций к векторам значений)
- `M` — матрица Грамма: `<g_i, g_j>`.
- `b` — вектор правой части: `<g_i, y>`.


### Решение системы линейных уравнений и предсказание для 2010 года

- Для каждого значения степени N строится базис.
- Строется матрица $M$ и правая часть $b$
- Вычисляются коэффициенты $c_i$ через решение системы $M \alpha = b$.
- Считаем население в 2010 году прямой подстновкой.
- Для каждого $N$ вычисляем относительную ошибку предсказания.

## Результаты аппроксимации

### Аппроксимация для $(x - 1910)^n$

|  N | Предсказано 2010 | Ошибка (%) |
| -: | ---------------: | ---------: |
|  1 |      289,729,384 |      6.159 |
|  2 |      312,470,336 |      1.206 |
|  3 |      309,020,979 |      0.089 |
|  4 |      305,706,175 |      0.984 |
|  5 |      340,607,732 |     10.320 |
|  6 |      376,772,506 |     22.033 |
|  7 |      265,449,224 |     14.023 |
|  8 |      476,324,978 |     54.278 |

### Аппроксимация для $((x - 1955)/45)^n$

|  N | Предсказано 2010 | Ошибка (%) |
| -: | ---------------: | ---------: |
|  1 |      289,729,384 |      6.159 |
|  2 |      312,470,336 |      1.206 |
|  3 |      309,020,979 |      0.089 |
|  4 |      305,706,175 |      0.984 |
|  5 |      340,607,732 |     10.320 |
|  6 |      376,772,506 |     22.033 |
|  7 |      265,449,233 |     14.023 |
|  8 |      476,322,119 |     54.277 |


---

## Графики

![Пункт б](/HW3/Task2/img/aprroxB.png)

![Пункт г](/HW3/Task2/img/approxD.png)

---

## Сравнение минимизируемого функционала $F$

### Для базиса $(x - 1910)^n$

|  N | Значение функционала $F$ | cond(M)        |
| -: | -----------------------: | -------------: |
|  1 |      $6.491\cdot10^{14}$ | $9.850\cdot10^{3}$  |
|  2 |      $8.492\cdot10^{13}$ | $9.497\cdot10^{7}$  |
|  3 |      $7.993\cdot10^{13}$ | $8.109\cdot10^{11}$ |
|  4 |      $7.839\cdot10^{13}$ | $6.438\cdot10^{15}$ |
|  5 |      $3.193\cdot10^{13}$ | $4.915\cdot10^{19}$ |
|  6 |      $2.138\cdot10^{13}$ | $2.731\cdot10^{23}$ |
|  7 |      $6.084\cdot10^{12}$ | $2.231\cdot10^{28}$ |
|  8 |      $7.043\cdot10^{11}$ | $1.465\cdot10^{30}$ |

### Для базиса $((x - 1955)/45)^n$

|  N | Значение функционала $F$ | cond(M)        |
| -: | -----------------------: | -------------: |
|  1 |      $6.491\cdot10^{14}$ | $2.455$       |
|  2 |      $8.492\cdot10^{13}$ | $10.93$       |
|  3 |      $7.993\cdot10^{13}$ | $49.62$       |
|  4 |      $7.839\cdot10^{13}$ | $279.4$       |
|  5 |      $3.193\cdot10^{13}$ | $1592$        |
|  6 |      $2.138\cdot10^{13}$ | $1.143\cdot10^{4}$ |
|  7 |      $6.084\cdot10^{12}$ | $9.182\cdot10^{4}$ |
|  8 |      $7.043\cdot10^{11}$ | $1.089\cdot10^{6}$ |

---

### Эквивалентность базисов

Для того, чтобы показать это, покажем что существует матрица перехода $S$, у которой $det(S)\neq0$ (у нее существует $S^{-1}$)

Выразим $u_k(x) = (x - 1910)^k$ через $v_j(x) = \left(\frac{x - 1955}{45}\right)^j.$ 

- $x - 1910 = (x - 1955) + 45$

- Подставим это в $(x-1910)^k$:
$$(x - 1910)^k = \big((x - 1955) + 45\big)^k$$

- Используем бином Ньютона:

$$((x - 1955) + 45)^k = \sum_{j=0}^{k} \binom{k}{j} (x-1955)^j \cdot 45^{k-j}$$

- Чтобы получить $v_j(x) = ((x-1955)/45)^j$, поделим $(x-1955)^j$ на $45^j$:

$$(x-1955)^j = 45^j \, v_j(x) \quad \Rightarrow \quad (x - 1910)^k = \sum_{j=0}^{k} \binom{k}{j} 45^k \, v_j(x)$$

- Для диагонального элемента $j=k$ получаем:

$$
a_{k,k} = \binom{k}{k} 45^k = 1 \cdot 45^k = 45^k \neq 0
$$

Получаем матрицу перехода, которая является нижнетреугольной и на диагонали находятся ненулевые коэффициенты, а значит она не вырождена.
Тогда каждый элемент базиса представляется линейной комбинацией векторов из другого базиса, а значит задаваемые ими подпространства одинаковы (при одинаковых N)

$$Lin\langle u_k\rangle = Lin\langle v_j\rangle$$

А значит **оба базиса задают одно и то же разложение** 

---

> Какой базис лучше? Как это можно понять?

- При одинаковом значении минимизируемого функционала  
  оба базиса дают **одинаковое качество аппроксимации**, ведь значение $F$ показывает суммарное квадратичное отклонение модели от данных.  
  Однако **число обусловленности матрицы $M$** сильно различается:  

  - Для базиса $(x-1910)^n$: $\mu(M)$ может быть большим ($10^{15}-10^{30}$ для больших N),  
    что делает решение чувствительным к округлениям.  
  - Для базиса $((x-1955)/45)^n$: $\mu(M)$ остаётся маленьким ($\sim 10^3 - 10^6$),  
    что обеспечивает **устойчивость вычисления коэффициентов**.

### Почему растёт ошибка при плохо обусловленном базисе

#### 1. Плохо обусловленная матрица

В МНК мы решаем систему  

$$M \alpha = b, \quad M_{ij} = \langle g_i, g_j \rangle$$

- Если базис $g_0, g_1, \dots$ содержит почти линейно зависимые векторы, элементы $M$ становятся очень большими или малыми.  
- Это делает матрицу **плохо обусловленной**, т.е. $\mu(M) \gg 1$.  

#### 2. Численная нестабильность
 
- При больших $\mu(M)$ даже маленькая ошибка округления в $b$ или $M$ сильно искажает решение $\alpha = M^{-1}b$.  
- В результате коэффициенты могут быть сильно неверными, несмотря на точные исходные данные.  

#### 3. Почему базис $(x-1910)^n$ хуже

- Элементы $(x-1910)^n$ для больших $n$ на годах $1910, \dots, 2000$ растут очень быстро (экспоненциально).  
- В матрице $M$ скалярные произведения создают огромные значения, сильно различающиеся по порядку величины.  
- Диагональные и недиагональные элементы сильно отличаются $\rightarrow$ $\mu(M)$ растёт.  

#### 4. Почему нормированный базис $((x-1955)/45)^n$ лучше

- Каждый вектор нормирован: $(x-1955)/45 \sim [-1,1]$.  
- Элементы матрицы $M$ примерно одного порядка.  
- Число обусловленности остаётся небольшим $\rightarrow$ решение устойчиво к погрешностям.  

#### 5. Вывод

- Плохо обусловленная матрица $\rightarrow$ коэффициенты МНК чувствительны к округлениям.  
- Хорошо нормированный базис снижает $\mu(M)$ и делает решение стабильным.


